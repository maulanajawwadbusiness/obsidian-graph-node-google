# Arnvoid System Documentation

## 1. Introduction
**Arnvoid** is a conversational graph interface designed for deep reasoning over complex knowledgebases. It acts as a "thinking partner" that lives inside the user's obsidian graph, providing context-aware synthesis and exploration.

The core flow is the **Paper Essence Pipeline**:
`Document (PDF/MD/TXT) -> AI Paper Analyzer -> 5 Key Nodes + Node Knowledge (Title/Summary) -> Interactive Graph -> Contextual Chat`.

## 2. UI Surface Map & Ownership

The application layers, ordered by z-index (lowest to highest):

1.  **The Canvas (Graph substrate)**
    *   **Rule**: Never under-reacts. If a panel or overlay is active, the canvas underneath MUST NOT receive pointer/wheel events.
    *   Owned by: `PhysicsEngine`.

2.  **Top-Left Brand (`BrandLabel`) & Bottom-Center Title (`MapTitleBlock`)**
    *   Subtle UI markers tied to the current document state.
    *   `MapTitleBlock` shows "Peta Pengetahuan 2D" and the AI-inferred title.
    *   **Rule**: `pointer-events: none` ensures they never steal clicks from the graph.

3.  **Node Popups (Context)**
    *   Floating cards appearing on node interaction. Entry point for MiniChat.
    *   Owned by: `PopupStore`.

4.  **Mini Chat (Quick Context)**
    *   Lightweight chat window attached to Node Popups.
    *   **Brain**: `PopupStore` wires this to real AI context.
    *   **Handoff**: Graduates conversation to Full Chat while preserving Node Knowledge.

5.  **Full Chatbar (Deep Reasoning)**
    *   Right-side panel for long-form synthesis.
    *   **Ownership**: Consumes all interaction within its bounds.
    *   Owned by: `FullChatStore`.

6.  **Analysis Overlay (`AnalysisOverlay`)**
    *   **Highest Layer**. Dims the screen during AI parsing/analysis.
    *   **Shielding Rule**: Blocks all pointer, wheel, and touch events to prevent graph disturbance during critical AI operations.

## 3. AI Architecture

Arnvoid uses a specialized AI factory (`src/ai/`) and localized modules for different tasks.

### Core Modules
*   **Paper Analyzer (`src/ai/paperAnalyzer.ts`)**: Distills documents into 1 Main Topic + 4 Detailed Points.
*   **FullChat AI (`src/fullchat/fullChatAi.ts`)**: Handles the reasoning panel and handoff prefill.
*   **MiniChat AI (`src/popup/PopupStore.tsx`)**: Directly integrated into the popup store for node-specific queries.

### Behavior Doctrine
*   **Mode Switch**: `VITE_AI_MODE='real'` vs `'mock'`.
*   **Abort Model**: Every AI loop uses an `AbortController`. Sending a new message or closing a panel instantly kills the in-flight request.
*   **Fake Streaming**: Since the client is non-streaming, we simulate character-by-character growth (Tick: 15ms, Chunk: 4chars) in the Store layer to maintain "living" feel.
*   **Fallback**: Timeouts (15s for FullChat, 2.5s for Prefill) trigger graceful mock fallbacks.

## 4. Context Doctrine

Intelligence is relative to context. We maintain three levels:

1.  **Node Knowledge**: A specific node's `sourceTitle` and `sourceSummary` generated by the analyzer. Lives in `node.meta`.
2.  **Document Context**: The full `documentText` and the metadata (inferred title) held in `DocumentStore`.
3.  **Handoff Context**: When moving from Mini -> Full, the `pendingContext` object preserves history + specific node knowledge so the reasoning is coherent.

## 5. Performance Doctrine (The Sacred 60)

*   **Hot Loops**: No network calls, no state updates inside the physics tick.
*   **Streaming**: Autosize and DOM updates for streaming text are throttled (~50ms) to prevent layout thrashing.
*   **Throttled Scroll**: `safeScrollToBottom` uses `requestAnimationFrame` and near-bottom detection to avoid jarring jumps.

